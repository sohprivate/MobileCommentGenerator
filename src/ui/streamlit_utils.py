"""
Streamlit UIãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°

Streamlit UIç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""

import json
import os
from typing import List, Dict, Any, Optional
from datetime import datetime
import pandas as pd
import streamlit as st


def load_locations() -> List[str]:
    """
    åœ°ç‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

    Returns:
        åœ°ç‚¹åã®ãƒªã‚¹ãƒˆ
    """
    try:
        # frontend/public/åœ°ç‚¹å.csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ­£ã—ã„åœ°ç‚¹ãƒã‚¹ã‚¿ãƒ¼ï¼‰
        csv_path = "frontend/public/åœ°ç‚¹å.csv"
        if os.path.exists(csv_path):
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦æ­£ã—ãè§£æ
            df = pd.read_csv(csv_path, encoding="utf-8")
            # åœ°ç‚¹åã‚«ãƒ©ãƒ ã®ã¿ã‚’å–å¾—
            if "åœ°ç‚¹å" in df.columns:
                locations = df["åœ°ç‚¹å"].tolist()
            else:
                # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„å ´åˆã¯æœ€åˆã®ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
                locations = df.iloc[:, 0].tolist()
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šsrc/data/Chiten.csvã‚’è©¦ã™
            fallback_path = "src/data/Chiten.csv"
            if os.path.exists(fallback_path):
                with open(fallback_path, "r", encoding="utf-8") as f:
                    locations = [line.strip() for line in f.readlines() if line.strip()]
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåœ°ç‚¹
                locations = [
                    "æ±äº¬",
                    "å¤§é˜ª",
                    "åå¤å±‹",
                    "ç¦å²¡",
                    "æœ­å¹Œ",
                    "ä»™å°",
                    "åºƒå³¶",
                    "é‚£è¦‡",
                    "æ–°æ½Ÿ",
                    "é‡‘æ²¢",
                    "é™å²¡",
                    "å²¡å±±",
                    "ç†Šæœ¬",
                    "é¹¿å…å³¶",
                    "é’æ£®",
                    "ç››å²¡",
                ]
    except Exception as e:
        st.error(f"åœ°ç‚¹ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåœ°ç‚¹
        locations = ["æ±äº¬", "å¤§é˜ª", "åå¤å±‹", "ç¦å²¡", "æœ­å¹Œ"]

    return sorted(locations)


def filter_locations(locations: List[str], query: str) -> List[str]:
    """
    åœ°ç‚¹ãƒªã‚¹ãƒˆã‚’æ¤œç´¢ã‚¯ã‚¨ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

    Args:
        locations: åœ°ç‚¹åã®ãƒªã‚¹ãƒˆ
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª

    Returns:
        ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸåœ°ç‚¹åã®ãƒªã‚¹ãƒˆ
    """
    if not query:
        return locations

    query_lower = query.lower()
    filtered = [loc for loc in locations if query_lower in loc.lower()]

    return filtered


def copy_to_clipboard(text: str) -> bool:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼

    Args:
        text: ã‚³ãƒ”ãƒ¼ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        æˆåŠŸã—ãŸå ´åˆTrue
    """
    # Streamlitã§ã®JavaScriptå®Ÿè¡Œ
    js_code = f"""
    <script>
    navigator.clipboard.writeText(`{text}`).then(function() {{
        console.log('Copying to clipboard was successful!');
    }}, function(err) {{
        console.error('Could not copy text: ', err);
    }});
    </script>
    """
    st.markdown(js_code, unsafe_allow_html=True)
    return True


def save_to_history(result: Dict[str, Any], location: str, llm_provider: str):
    """
    ç”Ÿæˆçµæœã‚’å±¥æ­´ã«ä¿å­˜

    Args:
        result: ç”Ÿæˆçµæœ
        location: åœ°ç‚¹å
        llm_provider: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å
    """
    history_file = "data/generation_history.json"

    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    history_item = {
        "timestamp": datetime.now().isoformat(),
        "location": location,
        "llm_provider": llm_provider,
        "final_comment": result.get("final_comment", ""),
        "success": result.get("success", False),
        "generation_metadata": result.get("generation_metadata", {}),
        "error": result.get("error", None),
    }

    try:
        # æ—¢å­˜å±¥æ­´ã®èª­ã¿è¾¼ã¿
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
        else:
            history = []

        # æ–°ã—ã„å±¥æ­´ã‚’è¿½åŠ 
        history.append(history_item)

        # å±¥æ­´ã‚µã‚¤ã‚ºã®åˆ¶é™ï¼ˆæœ€æ–°1000ä»¶ã¾ã§ï¼‰
        if len(history) > 1000:
            history = history[-1000:]

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs(os.path.dirname(history_file), exist_ok=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

    except Exception as e:
        st.error(f"å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")


def load_history() -> List[Dict[str, Any]]:
    """
    å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

    Returns:
        å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    history_file = "data/generation_history.json"

    try:
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
                return history
    except Exception as e:
        st.error(f"å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

    return []


def format_timestamp(dt: datetime) -> str:
    """
    ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

    Args:
        dt: datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Returns:
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ—¥æ™‚æ–‡å­—åˆ—
    """
    return dt.strftime("%Y/%m/%d %H:%M:%S")


def validate_api_keys() -> Dict[str, bool]:
    """
    APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼

    Returns:
        å„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®æ¤œè¨¼çµæœ
    """
    validation_results = {}

    # OpenAI
    openai_key = st.session_state.get("openai_api_key", "")
    validation_results["openai"] = bool(openai_key and len(openai_key) > 10)

    # Gemini
    gemini_key = st.session_state.get("gemini_api_key", "")
    validation_results["gemini"] = bool(gemini_key and len(gemini_key) > 10)

    # Anthropic
    anthropic_key = st.session_state.get("anthropic_api_key", "")
    validation_results["anthropic"] = bool(anthropic_key and len(anthropic_key) > 10)

    return validation_results


def get_theme_colors() -> Dict[str, str]:
    """
    ãƒ†ãƒ¼ãƒã‚«ãƒ©ãƒ¼ã‚’å–å¾—

    Returns:
        ã‚«ãƒ©ãƒ¼è¨­å®šã®è¾æ›¸
    """
    return {
        "primary": "#1E88E5",
        "secondary": "#E3F2FD",
        "success": "#4CAF50",
        "warning": "#FF9800",
        "error": "#F44336",
        "info": "#2196F3",
        "background": "#FFFFFF",
        "text": "#333333",
    }


def create_download_link(data: str, filename: str, mime_type: str = "text/plain") -> str:
    """
    ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ

    Args:
        data: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        mime_type: MIMEã‚¿ã‚¤ãƒ—

    Returns:
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã®HTML
    """
    import base64

    b64 = base64.b64encode(data.encode()).decode()
    href = f'<a href="data:{mime_type};base64,{b64}" download="{filename}">ğŸ“¥ {filename}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href


def export_history_csv(history: List[Dict[str, Any]]) -> str:
    """
    å±¥æ­´ã‚’CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    Args:
        history: å±¥æ­´ãƒ‡ãƒ¼ã‚¿

    Returns:
        CSVå½¢å¼ã®æ–‡å­—åˆ—
    """
    try:
        # DataFrameã«å¤‰æ›
        df_data = []
        for item in history:
            row = {
                "æ—¥æ™‚": item.get("timestamp", ""),
                "åœ°ç‚¹": item.get("location", ""),
                "LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼": item.get("llm_provider", ""),
                "ç”Ÿæˆã‚³ãƒ¡ãƒ³ãƒˆ": item.get("final_comment", ""),
                "æˆåŠŸ": item.get("success", False),
                "ã‚¨ãƒ©ãƒ¼": item.get("error", ""),
            }
            df_data.append(row)

        df = pd.DataFrame(df_data)
        return df.to_csv(index=False, encoding="utf-8-sig")

    except Exception as e:
        st.error(f"CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return ""


def get_statistics(history: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    å±¥æ­´çµ±è¨ˆã‚’å–å¾—

    Args:
        history: å±¥æ­´ãƒ‡ãƒ¼ã‚¿

    Returns:
        çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
    """
    if not history:
        return {}

    try:
        total_generations = len(history)
        successful_generations = sum(1 for item in history if item.get("success", False))
        success_rate = (
            (successful_generations / total_generations) * 100 if total_generations > 0 else 0
        )

        # åœ°ç‚¹åˆ¥çµ±è¨ˆ
        location_counts = {}
        for item in history:
            location = item.get("location", "ä¸æ˜")
            location_counts[location] = location_counts.get(location, 0) + 1

        # LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥çµ±è¨ˆ
        provider_counts = {}
        for item in history:
            provider = item.get("llm_provider", "ä¸æ˜")
            provider_counts[provider] = provider_counts.get(provider, 0) + 1

        # æœ€æ–°ã®ç”Ÿæˆæ—¥æ™‚
        latest_generation = max((item.get("timestamp", "") for item in history), default="")

        return {
            "total_generations": total_generations,
            "successful_generations": successful_generations,
            "success_rate": success_rate,
            "location_counts": location_counts,
            "provider_counts": provider_counts,
            "latest_generation": latest_generation,
        }

    except Exception as e:
        st.error(f"çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}


def reset_session_state():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    """
    keys_to_reset = ["current_result", "is_generating", "generation_history"]

    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]


def handle_error(error: Exception, context: str = ""):
    """
    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

    Args:
        error: ç™ºç”Ÿã—ãŸä¾‹å¤–
        context: ã‚¨ãƒ©ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    """
    error_message = f"{context}: {str(error)}" if context else str(error)
    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_message}")

    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆã¯è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
    if st.session_state.get("debug_mode", False):
        with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
            st.exception(error)
