"""
å‡ºåŠ›ãƒãƒ¼ãƒ‰

æœ€çµ‚çµæœã‚’æ•´å½¢ã—ã¦JSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹LangGraphãƒãƒ¼ãƒ‰
"""

from typing import Dict, Any, List, Optional
import logging
from datetime import datetime, timedelta
import json

from src.data.comment_generation_state import CommentGenerationState
from src.data.forecast_cache import ForecastCache

logger = logging.getLogger(__name__)


def _get_weather_timeline(location_name: str, base_datetime: datetime) -> Dict[str, Any]:
    """äºˆå ±åŸºæº–æ™‚åˆ»ã®å‰å¾Œã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        location_name: åœ°ç‚¹å
        base_datetime: äºˆå ±åŸºæº–æ™‚åˆ»
        
    Returns:
        æ™‚ç³»åˆ—ã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿
    """
    from src.data.forecast_cache import ensure_jst
    
    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’ç¢ºä¿
    base_datetime = ensure_jst(base_datetime)
    
    timeline_data: Dict[str, Any] = {
        "future_forecasts": [],
        "past_forecasts": [],
        "base_time": base_datetime.isoformat()
    }
    
    try:
        cache = ForecastCache()
        
        # æœªæ¥ã®äºˆå ±ãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ©ç”¨å¯èƒ½ãªç¯„å›²ã§å–å¾—ï¼‰
        future_times = []
        # ã¾ãš24æ™‚é–“å…ˆã¾ã§è©¦è¡Œã—ã€åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        for hours in range(3, 25, 3):  # 3, 6, 9, 12, 15, 18, 21, 24æ™‚é–“å¾Œ
            future_time = base_datetime + timedelta(hours=hours)
            future_times.append((future_time, f"+{hours}h"))
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ã‚’äº‹å‰ãƒã‚§ãƒƒã‚¯
        available_count = 0
        for future_time, label in future_times:
            try:
                forecast = cache.get_forecast_at_time(location_name, future_time)
                if forecast:
                    available_count += 1
            except:
                pass
        
        logger.info(f"åˆ©ç”¨å¯èƒ½ãªæœªæ¥äºˆå ±ãƒ‡ãƒ¼ã‚¿: {available_count}ä»¶")
        
        for future_time, label in future_times:
            try:
                forecast = cache.get_forecast_at_time(location_name, future_time)
                if forecast:
                    timeline_data["future_forecasts"].append({
                        "time": future_time.strftime("%m/%d %H:%M"),
                        "label": label,
                        "weather": forecast.weather_description,
                        "temperature": forecast.temperature,
                        "precipitation": forecast.precipitation
                    })
                    logger.debug(f"æœªæ¥äºˆå ±å–å¾—æˆåŠŸ: {label} at {future_time}")
                else:
                    logger.warning(f"æœªæ¥äºˆå ±ãƒ‡ãƒ¼ã‚¿ãªã—: {label} at {future_time}")
            except Exception as e:
                logger.warning(f"æœªæ¥ã®äºˆå ±å–å¾—ã‚¨ãƒ©ãƒ¼ ({label}): {e}")
        
        # éå»ã®äºˆå ±ãƒ‡ãƒ¼ã‚¿ï¼ˆ12æ™‚é–“å‰ã‹ã‚‰ç¾åœ¨ã¾ã§ã€3æ™‚é–“ã”ã¨ï¼‰
        past_times = []
        for hours in range(-12, 1, 3):  # -12, -9, -6, -3, 0æ™‚é–“
            past_time = base_datetime + timedelta(hours=hours)
            label = f"{hours:+d}h" if hours != 0 else "åŸºæº–æ™‚åˆ»"
            past_times.append((past_time, label))
        
        for past_time, label in past_times:
            try:
                forecast = cache.get_forecast_at_time(location_name, past_time)
                if forecast:
                    timeline_data["past_forecasts"].append({
                        "time": past_time.strftime("%m/%d %H:%M"),
                        "label": label,
                        "weather": forecast.weather_description,
                        "temperature": forecast.temperature,
                        "precipitation": forecast.precipitation
                    })
            except Exception as e:
                logger.warning(f"éå»ã®äºˆå ±å–å¾—ã‚¨ãƒ©ãƒ¼ ({label}): {e}")
        
        # ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããŸå ´åˆã®ã¿çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        all_forecasts = timeline_data["future_forecasts"] + timeline_data["past_forecasts"]
        if all_forecasts:
            temps = [f["temperature"] for f in all_forecasts if f["temperature"] is not None]
            precipitations = [f["precipitation"] for f in all_forecasts if f["precipitation"] is not None]
            
            timeline_data["summary"] = {
                "temperature_range": f"{min(temps):.1f}Â°Cã€œ{max(temps):.1f}Â°C" if temps else "ãƒ‡ãƒ¼ã‚¿ãªã—",
                "max_precipitation": f"{max(precipitations):.1f}mm" if precipitations else "0mm",
                "weather_pattern": _analyze_weather_pattern(all_forecasts)
            }
    
    except Exception as e:
        logger.error(f"å¤©æ°—ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        timeline_data["error"] = str(e)
    
    return timeline_data


def _analyze_weather_pattern(forecasts: List[Dict[str, Any]]) -> str:
    """å¤©æ°—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
    
    Args:
        forecasts: äºˆå ±ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        
    Returns:
        å¤©æ°—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èª¬æ˜
    """
    if not forecasts:
        return "ãƒ‡ãƒ¼ã‚¿ãªã—"
    
    weather_conditions = [f["weather"] for f in forecasts if f["weather"]]
    
    # æ‚ªå¤©å€™ã®æ¤œå‡º
    severe_conditions = ["å¤§é›¨", "åµ", "é›·", "è±ªé›¨", "æš´é¢¨", "å°é¢¨"]
    rain_conditions = ["é›¨", "å°é›¨", "ä¸­é›¨"]
    
    has_severe = any(any(severe in weather for severe in severe_conditions) for weather in weather_conditions)
    has_rain = any(any(rain in weather for rain in rain_conditions) for weather in weather_conditions)
    
    if has_severe:
        return "æ‚ªå¤©å€™æ³¨æ„"
    elif has_rain:
        return "é›¨å¤©ç¶šã"
    elif len(set(weather_conditions)) <= 2:
        return "å®‰å®šã—ãŸå¤©æ°—"
    else:
        return "å¤‰ã‚ã‚Šã‚„ã™ã„å¤©æ°—"


def output_node(state: CommentGenerationState) -> CommentGenerationState:
    """
    æœ€çµ‚çµæœã‚’JSONå½¢å¼ã§å‡ºåŠ›

    Args:
        state: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹

    Returns:
        å‡ºåŠ›å½¢å¼ã«æ•´å½¢ã•ã‚ŒãŸçŠ¶æ…‹
    """
    logger.info("OutputNode: å‡ºåŠ›å‡¦ç†ã‚’é–‹å§‹")

    try:
        # å®Ÿè¡Œæ™‚é–“ã®è¨ˆç®—
        execution_start = state.generation_metadata.get("execution_start_time")
        execution_end = datetime.now()
        execution_time_ms = 0

        if execution_start:
            # execution_startãŒæ–‡å­—åˆ—ã®å ´åˆã¯datetimeã«å¤‰æ›
            if isinstance(execution_start, str):
                try:
                    execution_start = datetime.fromisoformat(execution_start.replace("Z", "+00:00"))
                except:
                    execution_start = None

            # datetimeå‹ã®å ´åˆã®ã¿è¨ˆç®—
            if isinstance(execution_start, datetime):
                execution_time_delta = execution_end - execution_start
                execution_time_ms = int(execution_time_delta.total_seconds() * 1000)

        # æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆã®ç¢ºå®š
        final_comment = _determine_final_comment(state)
        state.final_comment = final_comment

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        generation_metadata = _create_generation_metadata(state, execution_time_ms)
        state.generation_metadata = generation_metadata

        # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
        output_data = {"final_comment": final_comment, "generation_metadata": generation_metadata}

        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³æƒ…å ±ã®è¿½åŠ 
        if state.generation_metadata.get("include_debug_info", False):
            output_data["debug_info"] = _create_debug_info(state)

        # JSONå½¢å¼ã¸ã®å¤‰æ›
        state.update_metadata("output_json", json.dumps(output_data, ensure_ascii=False, indent=2))

        # æˆåŠŸãƒ­ã‚°
        location_info = f"location={state.location_name}" if state.location_name else "location=unknown"
        logger.info(
            f"å‡ºåŠ›å‡¦ç†å®Œäº†: {location_info}, "
            f"comment_length={len(final_comment)}, "
            f"execution_time={execution_time_ms}ms, "
            f"retry_count={state.retry_count}"
        )

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        _cleanup_state(state)

        state.update_metadata("output_processed", True)

    except Exception as e:
        logger.error(f"å‡ºåŠ›å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        state.errors = state.errors + [f"OutputNode: {str(e)}"]
        state.update_metadata("output_processed", False)

        # ã‚¨ãƒ©ãƒ¼æ™‚ã®å‡ºåŠ›
        state.update_metadata(
            "output_json",
            json.dumps(
                {
                    "error": str(e),
                    "final_comment": None,
                    "generation_metadata": {
                        "error": str(e),
                        "execution_time_ms": 0,
                        "errors": state.errors,
                    },
                },
                ensure_ascii=False,
            ),
        )

    return state


def _determine_final_comment(state: CommentGenerationState) -> str:
    """
    æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®š

    å„ªå…ˆé †ä½:
    1. generated_commentï¼ˆLLMç”Ÿæˆï¼‰
    2. selected_pair ã® weather_comment
    3. ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
    """
    logger.critical(f"ğŸš¨ _determine_final_comment é–‹å§‹")
    logger.critical(f"ğŸš¨ state.generated_comment = '{getattr(state, 'generated_comment', None)}'")
    logger.critical(f"ğŸš¨ state.selected_pair = {getattr(state, 'selected_pair', None)}")
    
    # æœ€çµ‚å®‰å…¨ãƒã‚§ãƒƒã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿
    weather_data = state.weather_data
    final_comment = None
    
    # LLMç”Ÿæˆã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆ
    if state.generated_comment:
        final_comment = state.generated_comment
        logger.critical(f"ğŸš¨ generated_commentä½¿ç”¨: '{final_comment}'")
    else:
        # é¸æŠã•ã‚ŒãŸãƒšã‚¢ãŒã‚ã‚‹å ´åˆ - æ­£ã—ã„å½¢å¼ã§æ§‹æˆ
        selected_pair = state.selected_pair
        if selected_pair:
            weather_comment = ""
            advice_comment = ""
            
            if hasattr(selected_pair, "weather_comment") and selected_pair.weather_comment:
                weather_comment = selected_pair.weather_comment.comment_text
                
            if hasattr(selected_pair, "advice_comment") and selected_pair.advice_comment:
                advice_comment = selected_pair.advice_comment.comment_text
            
            logger.critical(f"ğŸš¨ é¸æŠã•ã‚ŒãŸãƒšã‚¢: weather='{weather_comment}', advice='{advice_comment}'")
            
            # æ­£ã—ã„å½¢å¼ã§çµåˆï¼ˆweather + å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ + adviceï¼‰
            if weather_comment and advice_comment:
                final_comment = f"{weather_comment}ã€€{advice_comment}"
                logger.critical(f"ğŸš¨ ãƒšã‚¢çµåˆä½¿ç”¨: '{final_comment}'")
            elif weather_comment:
                final_comment = weather_comment
                logger.critical(f"ğŸš¨ weather_commentã®ã¿ä½¿ç”¨: '{final_comment}'")
            elif advice_comment:
                final_comment = advice_comment
                logger.critical(f"ğŸš¨ advice_commentã®ã¿ä½¿ç”¨: '{final_comment}'")

    if not final_comment:
        # ã‚³ãƒ¡ãƒ³ãƒˆãŒç”Ÿæˆã§ããªã‹ã£ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼
        raise ValueError(
            "ã‚³ãƒ¡ãƒ³ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚LLMã¾ãŸã¯éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        )
    
    # ğŸš¨ æœ€çµ‚å®‰å…¨ãƒã‚§ãƒƒã‚¯ï¼šç‰¹æ®Šæ°—è±¡æ¡ä»¶ã«å¯¾ã™ã‚‹ä¸é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆçµ„ã¿åˆã‚ã›ã®ä¿®æ­£
    if weather_data and final_comment:
        current_weather = weather_data.weather_description.lower()
        temperature = weather_data.temperature if hasattr(weather_data, 'temperature') else 20.0
        weather_condition = weather_data.weather_condition.value
        
        # ç‰¹æ®Šæ°—è±¡æ¡ä»¶ã”ã¨ã®é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆç½®æ›
        if weather_condition == "thunder" or "é›·" in current_weather:
            logger.critical(f"ğŸš¨ é›·å¤©å€™æ¤œå‡º: '{final_comment}'")
            if "ã€€" in final_comment and not any(word in final_comment for word in ["é›·", "å±‹å†…", "å±é™º", "æ³¨æ„"]):
                parts = final_comment.split("ã€€")
                parts[0] = "é›·é›¨ã«è­¦æˆ’"
                parts[1] = "å±‹å†…ã§ã®é¿é›£ã‚’"
                final_comment = "ã€€".join(parts)
                logger.critical(f"ğŸš¨ é›·å¤©å€™ä¿®æ­£: '{final_comment}'")
                
        elif weather_condition == "fog" or "éœ§" in current_weather:
            logger.critical(f"ğŸš¨ éœ§å¤©å€™æ¤œå‡º: '{final_comment}'")
            if "ã€€" in final_comment and not any(word in final_comment for word in ["éœ§", "è¦–ç•Œ", "é‹è»¢", "æ³¨æ„"]):
                parts = final_comment.split("ã€€")
                parts[0] = "éœ§ã§è¦–ç•Œä¸è‰¯"
                parts[1] = "é‹è»¢ã«ã¯æ³¨æ„ã‚’"
                final_comment = "ã€€".join(parts)
                logger.critical(f"ğŸš¨ éœ§å¤©å€™ä¿®æ­£: '{final_comment}'")
                
        elif weather_condition in ["storm", "severe_storm"] or any(word in current_weather for word in ["åµ", "æš´é¢¨"]):
            logger.critical(f"ğŸš¨ åµå¤©å€™æ¤œå‡º: '{final_comment}'")
            if "ã€€" in final_comment and not any(word in final_comment for word in ["åµ", "æš´é¢¨", "å¼·é¢¨", "å±é™º"]):
                parts = final_comment.split("ã€€")
                parts[0] = "å¤§è’ã‚Œã®å¤©æ°—"
                parts[1] = "å¤–å‡ºã¯æ§ãˆã¦"
                final_comment = "ã€€".join(parts)
                logger.critical(f"ğŸš¨ åµå¤©å€™ä¿®æ­£: '{final_comment}'")
                
        elif weather_condition == "heavy_rain" or "å¤§é›¨" in current_weather:
            logger.critical(f"ğŸš¨ å¤§é›¨å¤©å€™æ¤œå‡º: '{final_comment}'")
            if "ã€€" in final_comment and not any(word in final_comment for word in ["å¤§é›¨", "æ´ªæ°´", "å† æ°´", "å±é™º"]):
                parts = final_comment.split("ã€€")
                parts[0] = "å¤§é›¨ã«è­¦æˆ’"
                parts[1] = "å† æ°´ã«æ³¨æ„ã‚’"
                final_comment = "ã€€".join(parts)
                logger.critical(f"ğŸš¨ å¤§é›¨å¤©å€™ä¿®æ­£: '{final_comment}'")
                
        # é›¨å¤©ã§ä¸é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆå…¨èˆ¬ã®ä¿®æ­£ï¼ˆæ‹¡å¼µç‰ˆï¼‰
        elif "é›¨" in current_weather:
            logger.critical(f"ğŸš¨ é›¨å¤©ã‚³ãƒ¡ãƒ³ãƒˆæ¤œè¨¼: '{final_comment}'")
            
            inappropriate_keywords = ["ç†±ä¸­ç—‡", "æš‘ã„", "ãƒ ã‚·ãƒ ã‚·", "èŠ±ç²‰", "æ—¥ç„¼ã‘", "ç´«å¤–ç·š", "æ•£æ­©", "ãƒ”ã‚¯ãƒ‹ãƒƒã‚¯", "å¤–éŠã³"]
            needs_correction = any(keyword in final_comment for keyword in inappropriate_keywords)
            
            if needs_correction:
                logger.critical(f"ğŸš¨ é›¨å¤©ä¸é©åˆ‡ã‚³ãƒ¡ãƒ³ãƒˆæ¤œå‡º: '{final_comment}'")
                
                if "ã€€" in final_comment:  # è¤‡åˆã‚³ãƒ¡ãƒ³ãƒˆã®å ´åˆ
                    parts = final_comment.split("ã€€")
                    
                    # å¤©æ°—ã‚³ãƒ¡ãƒ³ãƒˆéƒ¨åˆ†ã®ä¿®æ­£
                    if any(word in parts[0] for word in inappropriate_keywords):
                        if any(word in parts[0] for word in ["ç†±ä¸­ç—‡", "æš‘ã„", "ãƒ ã‚·ãƒ ã‚·"]):
                            parts[0] = "é›¨æ¨¡æ§˜"
                        elif "èŠ±ç²‰" in parts[0]:
                            parts[0] = "é›¨é™ã‚Š"
                        else:
                            parts[0] = "é›¨ã®ç©º"
                    
                    # ã‚¢ãƒ‰ãƒã‚¤ã‚¹éƒ¨åˆ†ã®ä¿®æ­£
                    if any(word in parts[1] for word in inappropriate_keywords):
                        if "èŠ±ç²‰" in parts[1]:
                            parts[1] = "é›¨ã«æ³¨æ„ã‚’"
                        elif any(word in parts[1] for word in ["ç†±ä¸­ç—‡", "æš‘ã„", "ãƒ ã‚·ãƒ ã‚·"]):
                            parts[1] = "å‚˜ã‚’ãŠå¿˜ã‚Œãªã"
                        elif any(word in parts[1] for word in ["æ•£æ­©", "ãƒ”ã‚¯ãƒ‹ãƒƒã‚¯", "å¤–éŠã³"]):
                            parts[1] = "å®¤å†…ã§éã”ãã†"
                        else:
                            parts[1] = "æ¿¡ã‚Œãªã„ã‚ˆã†æ³¨æ„"
                    
                    final_comment = "ã€€".join(parts)
                else:
                    final_comment = "é›¨ã®æ—¥ã¯ãŠæ°—ã‚’ã¤ã‘ã¦"
                
                logger.critical(f"ğŸš¨ é›¨å¤©ä¿®æ­£å¾Œ: '{final_comment}'")
            
    logger.critical(f"ğŸš¨ æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆç¢ºå®š: '{final_comment}'")
    return final_comment


def _create_generation_metadata(
    state: CommentGenerationState, execution_time_ms: int
) -> Dict[str, Any]:
    """
    ç”Ÿæˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    """
    metadata = {
        "execution_time_ms": execution_time_ms,
        "retry_count": state.retry_count,
        "request_id": state.generation_metadata.get("execution_context", {}).get(
            "request_id", "unknown"
        ),
        "generation_timestamp": datetime.now().isoformat(),
        "location_name": state.location_name,
        "target_datetime": state.target_datetime.isoformat() if state.target_datetime else None,
        "llm_provider": state.llm_provider or "none",
    }

    # å¤©æ°—æƒ…å ±ã®è¿½åŠ 
    weather_data = state.weather_data
    if weather_data:
        weather_info = {}
        
        # å¤©æ°—çŠ¶æ³ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        weather_condition = getattr(weather_data, "weather_description", None)
        if weather_condition and weather_condition != "ä¸æ˜":
            weather_info["weather_condition"] = weather_condition
        
        # æ°—æ¸©ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        temperature = getattr(weather_data, "temperature", None)
        if temperature is not None:
            weather_info["temperature"] = temperature
        
        # æ¹¿åº¦ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        humidity = getattr(weather_data, "humidity", None)
        if humidity is not None:
            weather_info["humidity"] = humidity
        
        # é¢¨é€Ÿï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        wind_speed = getattr(weather_data, "wind_speed", None)
        if wind_speed is not None:
            weather_info["wind_speed"] = wind_speed
        
        # å¤©æ°—ãƒ‡ãƒ¼ã‚¿ã®æ™‚åˆ»ï¼ˆäºˆå ±æ™‚åˆ»ï¼‰
        weather_datetime = getattr(weather_data, "datetime", None)
        if weather_datetime is not None:
            weather_info["weather_forecast_time"] = weather_datetime.isoformat()
            
            # æ™‚ç³»åˆ—ã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            location_name = state.location_name
            if location_name:
                try:
                    timeline_data = _get_weather_timeline(location_name, weather_datetime)
                    weather_info["weather_timeline"] = timeline_data
                    logger.info(f"æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ : éå»{len(timeline_data.get('past_forecasts', []))}ä»¶ã€æœªæ¥{len(timeline_data.get('future_forecasts', []))}ä»¶")
                except Exception as e:
                    logger.warning(f"æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    weather_info["weather_timeline"] = {"error": str(e)}
        
        # æœ‰åŠ¹ãªå¤©æ°—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
        if weather_info:
            metadata.update(weather_info)

    # é¸æŠã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆæƒ…å ±
    selected_pair = state.selected_pair
    if selected_pair:
        metadata["selected_past_comments"] = _extract_selected_comments(selected_pair)
        metadata["similarity_score"] = getattr(selected_pair, "similarity_score", 0.0)
        metadata["selection_reason"] = getattr(selected_pair, "selection_reason", "")

    # æ¤œè¨¼çµæœ
    validation_result = state.validation_result
    if validation_result:
        metadata["validation_passed"] = getattr(validation_result, "is_valid", False)
        metadata["validation_score"] = getattr(validation_result, "total_score", 0.0)

    # ã‚¨ãƒ©ãƒ¼ã¨è­¦å‘Š
    if state.errors:
        metadata["errors"] = state.errors
    if state.warnings:
        metadata["warnings"] = state.warnings

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
    user_preferences = state.generation_metadata.get("user_preferences", {})
    if user_preferences:
        metadata["style"] = user_preferences.get("style", "casual")
        metadata["length"] = user_preferences.get("length", "medium")

    return metadata


def _extract_selected_comments(selected_pair: Any) -> List[Dict[str, str]]:
    """
    é¸æŠã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’æŠ½å‡º
    """
    comments = []

    # å¤©æ°—ã‚³ãƒ¡ãƒ³ãƒˆ
    weather_comment = getattr(selected_pair, "weather_comment", None)
    if weather_comment and hasattr(weather_comment, "comment_text"):
        comment_dict = {
            "text": weather_comment.comment_text,
            "type": "weather_comment",
        }
        
        # æ°—æ¸©ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        temperature = getattr(weather_comment, "temperature", None)
        if temperature is not None:
            comment_dict["temperature"] = temperature
        
        # å¤©æ°—çŠ¶æ³ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        weather_condition = getattr(weather_comment, "weather_condition", None)
        if weather_condition and weather_condition != "ä¸æ˜":
            comment_dict["weather_condition"] = weather_condition
        
        comments.append(comment_dict)

    # ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚³ãƒ¡ãƒ³ãƒˆ
    advice_comment = getattr(selected_pair, "advice_comment", None)
    if advice_comment and hasattr(advice_comment, "comment_text"):
        comment_dict = {
            "text": advice_comment.comment_text,
            "type": "advice",
        }
        
        # æ°—æ¸©ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        temperature = getattr(advice_comment, "temperature", None)
        if temperature is not None:
            comment_dict["temperature"] = temperature
        
        # å¤©æ°—çŠ¶æ³ï¼ˆæœ‰åŠ¹ãªå€¤ã®ã¿è¿½åŠ ï¼‰
        weather_condition = getattr(advice_comment, "weather_condition", None)
        if weather_condition and weather_condition != "ä¸æ˜":
            comment_dict["weather_condition"] = weather_condition
        
        comments.append(comment_dict)

    return comments


# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆé–¢æ•°ã¯å‰Šé™¤ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ãŸã‚ä¸è¦ï¼‰


def _create_debug_info(state: CommentGenerationState) -> Dict[str, Any]:
    """
    ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ä½œæˆ
    """
    return {
        "state_keys": [attr for attr in dir(state) if not attr.startswith("_")],
        "retry_history": state.generation_metadata.get("evaluation_history", []),
        "node_execution_times": state.generation_metadata.get("node_execution_times", {}),
        "api_call_count": state.generation_metadata.get("api_call_count", 0),
        "cache_hits": state.generation_metadata.get("cache_hits", 0),
        "total_past_comments": len(state.past_comments) if state.past_comments else 0,
        "workflow_version": state.generation_metadata.get("execution_context", {}).get(
            "api_version", "unknown"
        ),
    }


def _cleanup_state(state: CommentGenerationState):
    """
    ä¸è¦ãªä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

    ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã€å¤§ããªä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    # å¤§ããªãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤å€™è£œ
    cleanup_keys = [
        "past_comments",  # éå»ã‚³ãƒ¡ãƒ³ãƒˆã®å¤§é‡ãƒ‡ãƒ¼ã‚¿
        "all_weather_data",  # è©³ç´°ãªå¤©æ°—ãƒ‡ãƒ¼ã‚¿
        "candidate_pairs",  # è©•ä¾¡å‰ã®å€™è£œãƒšã‚¢
        "evaluation_details",  # è©³ç´°ãªè©•ä¾¡æƒ…å ±
    ]

    for key in cleanup_keys:
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å†…ã®å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if key in state.generation_metadata:
            value = state.generation_metadata[key]
            if isinstance(value, (list, dict)) and len(str(value)) > 10000:  # 10KBä»¥ä¸Š
                logger.debug(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {key} ã‚’å‰Šé™¤")
                del state.generation_metadata[key]


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
__all__ = ["output_node"]
